# Workflow optimisation for reproducible science in ecology and environmental science

This serves as an open-access repository for the forthcoming lecture entitled 'Workflow Optimization for Reproducible Science in Ecology and Environmental Science,' scheduled to be hosted by the University of the Aegean on October 26, 2023. 

Within this repository, you can find all the course materials, references, and lecture handouts. Additionally, I envision this repository to serve as a practical demonstration of building and structuring a course from the ground up in an open and reproducible environment.

## Inspiration and background information:
Throughout my academic journey in the field of ecology, I had the privilege of participating in numerous research projects and meeting extraordinary collaborators, many of whom evolved into friendships. Frequently, I found myself actively seeking out discussions that pertained to ecological research, with a particular emphasis on subjects related to the computational dimension of our field. These interactions allowed me to explore and engage with the intricate aspects of ecological science, broadening my perspective and deepening my understanding of this dynamic discipline. Once I had the opportunity to debate with my classmate Yves. He was noticeably vexed by an assignment for our master's program, and his frustration led to a rather comical moment of exasperation for him and very inspirational for me: “I don't understand this. When I decided to do ecology I thought I would be in the jungle or in a natural ecosystem collecting data or obsering pandas. I want action not programming and statistics”. Since then I met amazing ecologists, very skilled in the field-work but very often frustrated with the amount of statistical knowledge they had to cope with. Over a course of four years dedicated to ecology, I began to discern that there is a broader difficulty and frustration among junior ecologists to deal with the computational aspect of our field. The way I approach this observation is relevant to advancements and changes that took place during the last decade. Worldwide data volume doubled nine times between 2006 and 2011 with this trend to continue exponentially this decade ([Farley et. al 2018](https://academic.oup.com/bioscience/article/68/8/563/5049569)). Ecology as earth science entered the era of big data as well. Ecological data are increasing due to a) continues data accumulation from earth observing systems (satelites), b) aggregation of small scientific projects into global, with collaborations expanding across continents (NutNet, DRAGNet), c) increasing interest and funding into long-term ecological monitoring networks (LTER; LFDP), d) citizen science (i.e. iNaturalist, GBIF). Overaccumulation of data poses several challenges for ecologists, with a background mainly in biology and not computer science ([Strømme et. al. 2022](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010356)). As a consequence, traditional and popular statistical analyses and data cleaning methods are slowly becoming either tedious or useless. From viewing and removing NAs in a simple dataset using spreadsheets to distributing big-sized spreadsheets via e-mail and to analyzing in a local computer with low computer power. Additionally, advancements in Artificial intelligence (AI) and the public availability of AI tools to everyone (such as bard and ChatGPT) pose more challenges to ecologists. To achieve a head start, we should openly address issues emerging from AI advancements and find out how these tools can be utilized in improving ecologists’ workflow ([Poisot T. et. al. 2023](https://www.authorea.com/users/6513/articles/663338-the-future-of-ecological-research-will-not-be-fully-automated)). In my opinion, very often, ecologists as they try to interpret the natural world, pay less attention to improving their workflow and their scripts, although their results are the outcome of a programing language (i.e. R, python or julia). And this point of view generated the idea for this lecture!

## Further reading:
Here, you can access a list of references and a compilation of courses I have previously attended that have inspired the content of this lecture:

Peer-reviewed articles:
- **[A simple kit to use computational notebooks for more openness, reproducibility, and productivity in research](https://journals.plos.org/ploscompbiol/article?id=10.1371/journal.pcbi.1010356)** and the corresponding GitHub [repository](https://github.com/FellowsFreiesWissen/computational_notebooks) with free code!
- **[Not just for programmers: How GitHub can accelerate collaborative and reproducible research in ecology and evolution](https://besjournals.onlinelibrary.wiley.com/doi/10.1111/2041-210X.14108)**
- [Evaluating the popularity of R in ecology](https://esajournals.onlinelibrary.wiley.com/doi/10.1002/ecs2.2567)
- [Close to open—Factors that hinder and promote open science in ecology research and education](https://journals.plos.org/plosone/article?id=10.1371/journal.pone.0278339)
- [Open science, reproducibility, and transparency in ecology](https://esajournals.onlinelibrary.wiley.com/doi/10.1002/eap.1822)
- [Low availability of code in ecology: A call for urgent action](https://journals.plos.org/plosbiology/article?id=10.1371/journal.pbio.3000763)
- [The future of ecological research will not be (fully) automated](https://www.authorea.com/users/6513/articles/663338-the-future-of-ecological-research-will-not-be-fully-automated)
  
Various online resources:
- [Reproducible Data Science](https://ecorepsci.github.io/reproducible-science/index.html)
- [How to use R Markdown ](https://www.rforecology.com/post/how-to-use-rmarkdown-part-one/?fbclid=IwAR0Axz3yb5Ql0Z0Koz6baJnN3POa6ut4FNo1jbJPOB4NWXeyNSVMXwMZDeM) 
- [Tidy data for efficiency, reproducibility, and collaboration](https://openscapes.org/blog/2020-10-12-tidy-data/)
- [Some good practices for research with R](https://github.com/etiennebacher/good-practices)




